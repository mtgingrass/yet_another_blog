<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>scrape on Mark Gingrass Blog</title>
    <link>/tags/scrape/</link>
    <description>Recent content in scrape on Mark Gingrass Blog</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en-us</language>
    <lastBuildDate>Sat, 09 Dec 2017 20:50:34 +0000</lastBuildDate>
    
	<atom:link href="/tags/scrape/index.xml" rel="self" type="application/rss+xml" />
    
    
    <item>
      <title>Data Cleanup with Solar Radiation Data Set</title>
      <link>/post/2017/12/09/data-cleanup-solar-radiation-data-set/</link>
      <pubDate>Sat, 09 Dec 2017 20:50:34 +0000</pubDate>
      
      <guid>/post/2017/12/09/data-cleanup-solar-radiation-data-set/</guid>
      <description>Purpose Before you can run a statistical analysis, you may have to clean data. This post is all about using some techniques to clean data. This is not necessarily the best way, or even the correct way to do this; however, it is mean to generate your own ideas for cleaning data in the future.
 Data Location The data comes from the Kaggle site here. It contains over 32,000 observations of Solar Radiation data.</description>
    </item>
    
    <item>
      <title>Data Cleanup with Solar Radiation Data Set</title>
      <link>/post/2017/12/09/data-cleanup-solar-radiation-data-set/</link>
      <pubDate>Sat, 09 Dec 2017 20:50:34 +0000</pubDate>
      
      <guid>/post/2017/12/09/data-cleanup-solar-radiation-data-set/</guid>
      <description>Purpose Before you can run a statistical analysis, you may have to clean data. This post is all about using some techniques to clean data. This is not necessarily the best way, or even the correct way to do this; however, it is mean to generate your own ideas for cleaning data in the future.
Data Location The data comes from the Kaggle site here. It contains over 32,000 observations of Solar Radiation data.</description>
    </item>
    
    <item>
      <title>R Lowercase Function in Corpus Error Solved</title>
      <link>/post/2017/12/07/r-tm_maptweet-corpus-content_transformertolower-error-solved/</link>
      <pubDate>Thu, 07 Dec 2017 05:18:33 +0000</pubDate>
      
      <guid>/post/2017/12/07/r-tm_maptweet-corpus-content_transformertolower-error-solved/</guid>
      <description>In my last video tutorial, I demonstrated the steps to tap into the power of the Twitter API to download Tweets based on search terms and import them into R. My plan was to make a follow up video showing how to clean the twitter data and run a Word Cloud on common terms.
However, I ran into a slight snag early on.
The code was supposed to be simple and quick.</description>
    </item>
    
    <item>
      <title>R Lowercase Function in Corpus Error Solved</title>
      <link>/post/2017/12/07/r-tm_maptweet-corpus-content_transformertolower-error-solved/</link>
      <pubDate>Thu, 07 Dec 2017 05:18:33 +0000</pubDate>
      
      <guid>/post/2017/12/07/r-tm_maptweet-corpus-content_transformertolower-error-solved/</guid>
      <description>In my last video tutorial, I demonstrated the steps to tap into the power of the Twitter API to download Tweets based on search terms and import them into R. My plan was to make a follow up video showing how to clean the twitter data and run a Word Cloud on common terms.
However, I ran into a slight snag early on.
The code was supposed to be simple and quick.</description>
    </item>
    
    <item>
      <title>R Programming Twitter Scraper</title>
      <link>/post/2017/11/21/r-programming-twitter-scraper/</link>
      <pubDate>Tue, 21 Nov 2017 17:07:51 +0000</pubDate>
      
      <guid>/post/2017/11/21/r-programming-twitter-scraper/</guid>
      <description>Create a Twitter Scrapper using R programming language in these very simple steps:
[embed]https://youtu.be/1_K01qD4Exw[/embed]
Follow these simple steps to start srapping:
Create Twitter API Application first: https://apps.twitter.com/.
 Copy the code below into an R script.
 Install packages “twitteR” and “ROAuth” if required.
 Change the search terms to your liking.
 library(twitteR) library(ROAuth)
Set API Keys api_key &amp;lt;- “XXXXXXXXXXXXXXXXXXXX” api_secret &amp;lt;- “xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx”
access_token &amp;lt;- “xxxxxxxxxx-xxxxxxxxxxxxxxxxxxxxxxxxxxxxxx” access_token_secret &amp;lt;- “xxxxxxxxxxxxxxxxxxxxxxxxxxxx”</description>
    </item>
    
    <item>
      <title>R Programming Twitter Scraper</title>
      <link>/post/2017/11/21/r-programming-twitter-scraper/</link>
      <pubDate>Tue, 21 Nov 2017 17:07:51 +0000</pubDate>
      
      <guid>/post/2017/11/21/r-programming-twitter-scraper/</guid>
      <description>Create a Twitter Scrapper using R programming language in these very simple steps:
[embed]https://youtu.be/1_K01qD4Exw[/embed]
Follow these simple steps to start srapping:
 Create Twitter API Application first: https://apps.twitter.com/.
 Copy the code below into an R script.
 Install packages &amp;ldquo;twitteR&amp;rdquo; and &amp;ldquo;ROAuth&amp;rdquo; if required.
 Change the search terms to your liking.
 library(twitteR) library(ROAuth)
Set API Keys api_key &amp;lt;- &amp;ldquo;XXXXXXXXXXXXXXXXXXXX&amp;rdquo; api_secret &amp;lt;- &amp;ldquo;xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx&amp;rdquo;
access_token &amp;lt;- &amp;ldquo;xxxxxxxxxx-xxxxxxxxxxxxxxxxxxxxxxxxxxxxxx&amp;rdquo; access_token_secret &amp;lt;- &amp;ldquo;xxxxxxxxxxxxxxxxxxxxxxxxxxxx&amp;rdquo;</description>
    </item>
    
  </channel>
</rss>